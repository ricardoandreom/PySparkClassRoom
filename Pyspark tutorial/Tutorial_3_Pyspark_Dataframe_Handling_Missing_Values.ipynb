{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ded0783b",
      "metadata": {
        "id": "ded0783b"
      },
      "source": [
        "### Pyspark Handling Missing Values\n",
        "- Dropping Columns\n",
        "- Dropping Rows\n",
        "- Various Parameter In Dropping functionalities\n",
        "- Handling Missing values by Mean, Median And Mode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_3ChimyjYLi",
        "outputId": "2ba33faa-4475-4342-c37a-ba9297215aba"
      },
      "id": "G_3ChimyjYLi",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285397 sha256=35104631e7f120e557bcef83d4d2685148cd54892263f5b7ca8e952c964334d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "805e7382",
      "metadata": {
        "id": "805e7382"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark=SparkSession.builder.appName('Practise').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e48ebc07",
      "metadata": {
        "id": "e48ebc07"
      },
      "outputs": [],
      "source": [
        "df_pyspark=spark.read.csv('test2.csv',header=True,inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "53ab7bbc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53ab7bbc",
        "outputId": "5ec50d6e-28cd-439e-de4f-ac7b27e06039"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- Experience: integer (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ed677b30",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed677b30",
        "outputId": "7b590e8e-8cbc-4a87-e7eb-aec399761f2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+\n",
            "|     Name| age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|Sudhanshu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|null|      null| 40000|\n",
            "|     null|  34|        10| 38000|\n",
            "|     null|  36|      null|  null|\n",
            "+---------+----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "523d3c4e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "523d3c4e",
        "outputId": "b4d256e0-2edc-449a-f33a-de3160de62ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----------+------+\n",
            "| age|Experience|Salary|\n",
            "+----+----------+------+\n",
            "|  31|        10| 30000|\n",
            "|  30|         8| 25000|\n",
            "|  29|         4| 20000|\n",
            "|  24|         3| 20000|\n",
            "|  21|         1| 15000|\n",
            "|  23|         2| 18000|\n",
            "|null|      null| 40000|\n",
            "|  34|        10| 38000|\n",
            "|  36|      null|  null|\n",
            "+----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "##Drop the columns\n",
        "df_pyspark.drop('Name').show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9c041e07",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c041e07",
        "outputId": "0c6013fc-93c1-4bfd-d1f8-f65509add574"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+\n",
            "|     Name| age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|Sudhanshu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|null|      null| 40000|\n",
            "|     null|  34|        10| 38000|\n",
            "|     null|  36|      null|  null|\n",
            "+---------+----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Drop rows with NAs**"
      ],
      "metadata": {
        "id": "RFTvkQ45kBhw"
      },
      "id": "RFTvkQ45kBhw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36845e38",
      "metadata": {
        "id": "36845e38",
        "outputId": "d83cd6e3-cf96-46a5-a8fb-0b347a0d6e34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark.na.drop().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Drop row if there is any NA**"
      ],
      "metadata": {
        "id": "H4ie8yLXlDap"
      },
      "id": "H4ie8yLXlDap"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "156e41cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "156e41cf",
        "outputId": "e8ddb17e-8fbb-4c9a-86a3-3da71701b236"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### any==how\n",
        "df_pyspark.na.drop(how=\"any\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Keep rows with 3 or more non NAs**"
      ],
      "metadata": {
        "id": "MUkbjhLMlemy"
      },
      "id": "MUkbjhLMlemy"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "e9af0da0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9af0da0",
        "outputId": "d21071ee-8025-4d30-f0ed-57060b72b57a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "|     null| 34|        10| 38000|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "##threshold\n",
        "df_pyspark.na.drop(how=\"any\",thresh=3).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**drop NAs for a specific column**"
      ],
      "metadata": {
        "id": "wbOU-1i6mOlS"
      },
      "id": "wbOU-1i6mOlS"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "787fc949",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "787fc949",
        "outputId": "fa83ffb5-dbf1-43e1-c886-c1666b9736c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+----------+------+\n",
            "|     Name|age|Experience|Salary|\n",
            "+---------+---+----------+------+\n",
            "|    Krish| 31|        10| 30000|\n",
            "|Sudhanshu| 30|         8| 25000|\n",
            "|    Sunny| 29|         4| 20000|\n",
            "|     Paul| 24|         3| 20000|\n",
            "|   Harsha| 21|         1| 15000|\n",
            "|  Shubham| 23|         2| 18000|\n",
            "|     null| 34|        10| 38000|\n",
            "|     null| 36|      null|  null|\n",
            "+---------+---+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "##Subset\n",
        "df_pyspark.na.drop(how=\"any\",subset=['Age']).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "72bad9ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72bad9ba",
        "outputId": "b7e1d3b2-6c71-49d0-e6d6-965e761792f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+\n",
            "|     Name| age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|Sudhanshu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|null|      null| 40000|\n",
            "|     null|  34|        10| 38000|\n",
            "|     null|  36|      null|  null|\n",
            "+---------+----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### Filling the Missing Value\n",
        "df_pyspark.na.fill('Missing Values',['Experience','age']).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "64e01bb9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64e01bb9",
        "outputId": "058a85cc-462d-4447-e7dd-a1b412769f7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+\n",
            "|     Name| age|Experience|Salary|\n",
            "+---------+----+----------+------+\n",
            "|    Krish|  31|        10| 30000|\n",
            "|Sudhanshu|  30|         8| 25000|\n",
            "|    Sunny|  29|         4| 20000|\n",
            "|     Paul|  24|         3| 20000|\n",
            "|   Harsha|  21|         1| 15000|\n",
            "|  Shubham|  23|         2| 18000|\n",
            "|   Mahesh|null|      null| 40000|\n",
            "|     null|  34|        10| 38000|\n",
            "|     null|  36|      null|  null|\n",
            "+---------+----+----------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "b66832fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b66832fd",
        "outputId": "cc8fd9c8-2207-4b96-b6ed-97736bf24fca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- Experience: integer (nullable = true)\n",
            " |-- Salary: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_pyspark.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fill NAs with median values**"
      ],
      "metadata": {
        "id": "k4KkiGNUnG3E"
      },
      "id": "k4KkiGNUnG3E"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "e31190f2",
      "metadata": {
        "id": "e31190f2"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import Imputer\n",
        "\n",
        "imputer = Imputer(\n",
        "    inputCols=['age', 'Experience', 'Salary'],\n",
        "    outputCols=[\"{}_imputed\".format(c) for c in ['age', 'Experience', 'Salary']]\n",
        "    ).setStrategy(\"median\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "d84c4a3d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d84c4a3d",
        "outputId": "72f90097-15d5-421f-e251-fe5b02dcae26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----+----------+------+-----------+------------------+--------------+\n",
            "|     Name| age|Experience|Salary|age_imputed|Experience_imputed|Salary_imputed|\n",
            "+---------+----+----------+------+-----------+------------------+--------------+\n",
            "|    Krish|  31|        10| 30000|         31|                10|         30000|\n",
            "|Sudhanshu|  30|         8| 25000|         30|                 8|         25000|\n",
            "|    Sunny|  29|         4| 20000|         29|                 4|         20000|\n",
            "|     Paul|  24|         3| 20000|         24|                 3|         20000|\n",
            "|   Harsha|  21|         1| 15000|         21|                 1|         15000|\n",
            "|  Shubham|  23|         2| 18000|         23|                 2|         18000|\n",
            "|   Mahesh|null|      null| 40000|         29|                 4|         40000|\n",
            "|     null|  34|        10| 38000|         34|                10|         38000|\n",
            "|     null|  36|      null|  null|         36|                 4|         20000|\n",
            "+---------+----+----------+------+-----------+------------------+--------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Add imputation cols to df\n",
        "imputer.fit(df_pyspark).transform(df_pyspark).show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
